import streamlit as st
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
import torch

@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("robiulhasanjisan88/Bangla-QA-BERT")
    model = AutoModelForQuestionAnswering.from_pretrained("robiulhasanjisan88/Bangla-QA-BERT")
    model.eval()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    return tokenizer, model, device

tokenizer, model, device = load_model()

st.set_page_config(page_title="Chemistry AI Assistant", layout="centered")

# Dark theme CSS
st.markdown("""
<style>
    .stApp {
        background-color: #0d1117;
        color: #e6edf3;
        font-family: 'Segoe UI', sans-serif;
    }
    .chat-bubble-user {
        background-color: #1f6feb;
        color: white;
        padding: 12px 18px;
        border-radius: 12px;
        margin: 10px 0;
        text-align: right;
        max-width: 80%;
        word-wrap: break-word;
    }
    .chat-bubble-ai {
        background-color: #161b22;
        color: #e6edf3;
        border: 1px solid #30363d;
        padding: 12px 18px;
        border-radius: 12px;
        margin: 10px 0;
        text-align: left;
        max-width: 80%;
        word-wrap: break-word;
    }
    .footer {
        margin-top: 30px;
        font-size: 13px;
        text-align: center;
        color: #8b949e;
    }
    .stTextInput>div>div>input {
        background-color: #21262d;
        color: #f0f6fc;
        border: 1px solid #30363d;
        border-radius: 8px;
    }
    .stButton>button {
        background-color: #238636;
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.5rem 1rem;
    }
    .stButton>button:hover {
        background-color: #2ea043;
    }
</style>
""", unsafe_allow_html=True)

st.title("Chemistry AI Assistant")
st.write("Ask a chemistry question and get answers generated by the AI model.")

# Initialize chat history
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Clear chat button
if st.button("Clear Chat History"):
    st.session_state.chat_history = []

# Input box
user_input = st.text_input("Your Question:", placeholder="e.g. What is an atom?")

if user_input:
    st.session_state.chat_history.append(("user", user_input))

    # Since this is a QA model, you need to define a context too
    # For now, use a dummy context or load from database or file
    context = "Chemistry is the branch of science that studies the composition, structure, and properties of matter."

    inputs = tokenizer.encode_plus(user_input, context, return_tensors="pt").to(device)

    with torch.no_grad():
        outputs = model(**inputs)
        start_scores = outputs.start_logits
        end_scores = outputs.end_logits
        start = torch.argmax(start_scores)
        end = torch.argmax(end_scores) + 1
        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs["input_ids"][0][start:end]))

    if not answer.strip():
        answer = "Sorry, I couldn't generate an answer."

    st.session_state.chat_history.append(("ai", answer))

# Show chat history (latest at bottom)
for sender, msg in st.session_state.chat_history:
    bubble_class = "chat-bubble-user" if sender == "user" else "chat-bubble-ai"
    st.markdown(f"<div class='{bubble_class}'>{msg}</div>", unsafe_allow_html=True)

# Footer
st.markdown("<div class='footer'>Powered by Hugging Face & BERT</div>", unsafe_allow_html=True)
